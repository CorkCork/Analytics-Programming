## Module 6

### Problem Description

In this Module, I will be doing the following:

##### Part 1: .arff

Create a notebook that:

* Ingest the .arff data found at https://archive.ics.uci.edu/ml/datasets/phishing+websites#
* Describe the data using metadata found in the documentation on the same website mentioned above 
* Use pandas or numpy to support an analysis of the relationship between one or more characteristics and the outcome (phishing / non-phishing)
* Split the dataframe into two new dataframes -- one for phishing and one for non-phishing websites
* Save those two dataframes into .csvs for later use
* Use markdown cells to begin the notebook with an appropriate header, and explain to a naive stakeholder what I am doing along the way.

##### Part 2: Fixed Width

Create a notebook that:

* Ingest fixed-width data at https://catalog.data.gov/dataset/climate-prediction-center-cpc-monthly-u-s-selected-cities-precipitation-summary
* Clean up the data as required, removing any unwanted rows at the top and bottom and splitting any columns that need it 
* Describe the data globally using metadata found in the documentation on the same website 
* Use pandas to create a more easily read version of the data, with self-documenting variable names
* Write this neatened-up dataset to file as as csv
* Identify which city has the lowest year to date percent-of-normal (pct nml) value and which has the highest